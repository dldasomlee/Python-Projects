{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.cross_validation import KFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn import cross_validation\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000         NaN    0.000000   \n",
      "50%     446.000000    0.000000    3.000000         NaN    0.000000   \n",
      "75%     668.500000    1.000000    3.000000         NaN    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DaSom\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:3834: RuntimeWarning: Invalid value encountered in percentile\n",
      "  RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "titanic = pandas.read_csv(\"train.csv\")\n",
    "# Print the first 5 rows of the dataframe\n",
    "print(titanic.head(5))\n",
    "print(titanic.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic[\"Age\"] = titanic[\"Age\"].fillna(titanic[\"Age\"].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert non-numeric to numeric values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['male' 'female']\n"
     ]
    }
   ],
   "source": [
    "# Find all the genders \n",
    "print(titanic[\"Sex\"].unique())\n",
    "titanic.loc[titanic[\"Sex\"] == \"male\", \"Sex\"] = 0\n",
    "titanic.loc[titanic[\"Sex\"] == \"female\", \"Sex\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S' 'C' 'Q' nan]\n"
     ]
    }
   ],
   "source": [
    "# Find all \"Embarked\"\n",
    "print(titanic[\"Embarked\"].unique())\n",
    "titanic[\"Embarked\"] = titanic[\"Embarked\"].fillna(\"S\")\n",
    "titanic.loc[titanic[\"Embarked\"] == \"S\", \"Embarked\"] = 0\n",
    "titanic.loc[titanic[\"Embarked\"] == \"C\", \"Embarked\"] = 1\n",
    "titanic.loc[titanic[\"Embarked\"] == \"Q\", \"Embarked\"] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression and Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predict the target\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n",
    "\n",
    "# Initialize the algorithm \n",
    "alg = LinearRegression()\n",
    "# Generate cross validation folds \n",
    "# Set random_state to get the same splits\n",
    "kf = KFold(titanic.shape[0], n_folds=3, random_state=1)\n",
    "\n",
    "predictions = []\n",
    "for train, test in kf:\n",
    "    # Take the rows in the train folds\n",
    "    train_predictors = (titanic[predictors].iloc[train,:])\n",
    "    # The target used to train the algorithm\n",
    "    train_target = titanic[\"Survived\"].iloc[train]\n",
    "    # Train the algorithm using the predictors and target\n",
    "    alg.fit(train_predictors, train_target)\n",
    "    # Make predictions on the test fold\n",
    "    test_predictions = alg.predict(titanic[predictors].iloc[test,:])\n",
    "    predictions.append(test_predictions)\n",
    "# Concatenate three separate numpy arrays into one \n",
    "# Axis 0\n",
    "predictions = np.concatenate(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Percentage of correct predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.783389450056\n"
     ]
    }
   ],
   "source": [
    "# Map predictions to outcomes \n",
    "predictions[predictions > .5] = 1\n",
    "predictions[predictions <=.5] = 0\n",
    "accuracy = sum(map(lambda x, y: x == y, predictions, titanic[\"Survived\"]))/len(titanic[\"Survived\"])\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.787878787879\n"
     ]
    }
   ],
   "source": [
    "# Initialize the algorithm\n",
    "alg = LogisticRegression(random_state=1)\n",
    "# Compute the accuracy score\n",
    "scores = cross_validation.cross_val_score(alg, titanic[predictors], titanic[\"Survived\"], cv=3)\n",
    "# Take the mean of the scores \n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titanic_test = pandas.read_csv(\"test.csv\")\n",
    "titanic_test[\"Age\"] = titanic_test[\"Age\"].fillna(titanic[\"Age\"].median())\n",
    "titanic_test[\"Fare\"] = titanic_test[\"Fare\"].fillna(titanic_test[\"Fare\"].median())\n",
    "titanic_test.loc[titanic_test[\"Sex\"] == \"male\", \"Sex\"] = 0 \n",
    "titanic_test.loc[titanic_test[\"Sex\"] == \"female\", \"Sex\"] = 1\n",
    "titanic_test[\"Embarked\"] = titanic_test[\"Embarked\"].fillna(\"S\")\n",
    "\n",
    "titanic_test.loc[titanic_test[\"Embarked\"] == \"S\", \"Embarked\"] = 0\n",
    "titanic_test.loc[titanic_test[\"Embarked\"] == \"C\", \"Embarked\"] = 1\n",
    "titanic_test.loc[titanic_test[\"Embarked\"] == \"Q\", \"Embarked\"] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize the algorithm \n",
    "alg = LogisticRegression(random_state=1)\n",
    "\n",
    "# Train the algorithm using all the training data\n",
    "alg.fit(titanic[predictors], titanic[\"Survived\"])\n",
    "\n",
    "# Make predictions \n",
    "predictions = alg.predict(titanic_test[predictors])\n",
    "\n",
    "# Submission\n",
    "submission = pandas.DataFrame({\n",
    "        \"PassengerId\": titanic_test[\"PassengerId\"],\n",
    "        \"Survived\": predictions\n",
    "    })\n",
    "submission.to_csv(\"kaggle.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Result: About 79% of accuracy achieved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second trial with improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest and cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.785634118967\n"
     ]
    }
   ],
   "source": [
    "# Currently, I get 75% accuracy. Let's try to improve this\n",
    "\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n",
    "\n",
    "# Initialize the algorithm with the default paramters\n",
    "# n_estimators is the number of trees I want to make\n",
    "# min_samples_split is the minimum number of rows I need to make a split\n",
    "# min_samples_leaf is the minimum number of samples I can have at the place where a tree branch ends \n",
    "alg = RandomForestClassifier(random_state=1, n_estimators=10, min_samples_split=2, min_samples_leaf=1)\n",
    "\n",
    "# Compute the accuracy score  \n",
    "kf = cross_validation.KFold(titanic.shape[0], n_folds=3, random_state=1)\n",
    "scores = cross_validation.cross_val_score(alg, titanic[predictors], titanic[\"Survived\"], cv=kf)\n",
    "\n",
    "# Take the mean of the scores\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.81593714927\n"
     ]
    }
   ],
   "source": [
    "# Increase the number of trees \n",
    "alg = RandomForestClassifier(random_state=1, n_estimators=50, min_samples_split=4, min_samples_leaf=2)\n",
    "\n",
    "# Compute the accuracy score \n",
    "kf = cross_validation.KFold(titanic.shape[0], 3, random_state=1)\n",
    "scores = cross_validation.cross_val_score(alg, titanic[predictors], titanic[\"Survived\"], cv=kf)\n",
    "\n",
    "# Take the mean of the scores \n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate new features using 1) the length of the name and 2) the total number of people in a family\n",
    "titanic[\"FamilySize\"] = titanic[\"SibSp\"] + titanic[\"Parch\"]\n",
    "titanic[\"NameLength\"] = titanic[\"Name\"].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map each title to an integer value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr          517\n",
      "Miss        182\n",
      "Mrs         125\n",
      "Master       40\n",
      "Dr            7\n",
      "Rev           6\n",
      "Major         2\n",
      "Mlle          2\n",
      "Col           2\n",
      "Ms            1\n",
      "Don           1\n",
      "Sir           1\n",
      "Countess      1\n",
      "Capt          1\n",
      "Lady          1\n",
      "Mme           1\n",
      "Jonkheer      1\n",
      "Name: Name, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# A function to get the title from a name\n",
    "def get_title(name):\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "\n",
    "titles = titanic[\"Name\"].apply(get_title)\n",
    "print(pandas.value_counts(titles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     517\n",
      "2     183\n",
      "3     125\n",
      "4      40\n",
      "5       7\n",
      "6       6\n",
      "7       5\n",
      "10      3\n",
      "8       3\n",
      "9       2\n",
      "Name: Name, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Map each title to an integer.  Some titles are very rare so, compressed into the same codes as other titles\n",
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Dr\": 5, \"Rev\": 6, \"Major\": 7, \"Col\": 7, \"Mlle\": 8, \"Mme\": 8, \"Don\": 9, \"Lady\": 10, \"Countess\": 10, \"Jonkheer\": 10, \"Sir\": 9, \"Capt\": 7, \"Ms\": 2}\n",
    "for k,v in title_mapping.items():\n",
    "    titles[titles == k] = v\n",
    "\n",
    "print(pandas.value_counts(titles))\n",
    "\n",
    "titanic[\"Title\"] = titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map each last name to a family ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A dictionary mapping family name to id\n",
    "family_id_mapping = {}\n",
    "\n",
    "def get_family_id(row):\n",
    "    last_name = row[\"Name\"].split(\",\")[0]\n",
    "    family_id = \"{0}{1}\".format(last_name, row[\"FamilySize\"])\n",
    "    if family_id not in family_id_mapping:\n",
    "        if len(family_id_mapping) == 0:\n",
    "            current_id = 1\n",
    "        else:\n",
    "            current_id = (max(family_id_mapping.items(), key=operator.itemgetter(1))[1] + 1)\n",
    "        family_id_mapping[family_id] = current_id\n",
    "    return family_id_mapping[family_id]\n",
    "\n",
    "family_ids = titanic.apply(get_family_id, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1      800\n",
      " 14       8\n",
      " 149      7\n",
      " 63       6\n",
      " 50       6\n",
      " 59       6\n",
      " 17       5\n",
      " 384      4\n",
      " 27       4\n",
      " 25       4\n",
      " 162      4\n",
      " 8        4\n",
      " 84       4\n",
      " 340      4\n",
      " 43       3\n",
      " 269      3\n",
      " 58       3\n",
      " 633      2\n",
      " 167      2\n",
      " 280      2\n",
      " 510      2\n",
      " 90       2\n",
      " 83       1\n",
      " 625      1\n",
      " 376      1\n",
      " 449      1\n",
      " 498      1\n",
      " 588      1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# compress all of the families under 3 members into one code\n",
    "family_ids[titanic[\"FamilySize\"] < 3] = -1\n",
    "print(pandas.value_counts(family_ids))\n",
    "titanic[\"FamilyId\"] = family_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectKBest(k=5, score_func=<function f_classif at 0x000001D239E048C8>)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the best feature\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\", \"FamilySize\", \"Title\", \"FamilyId\", \"NameLength\"]\n",
    "\n",
    "# Perform feature selection\n",
    "selector = SelectKBest(f_classif, k=5)\n",
    "selector.fit(titanic[predictors], titanic[\"Survived\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfwAAAGvCAYAAAC+SGdKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nktQAJnxJkhrg/we8fsoWlvXOFgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d23a426978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the raw p-values for each feature, and transform from p-values into scores\n",
    "scores = -np.log10(selector.pvalues_)\n",
    "plt.bar(range(len(predictors)), scores)\n",
    "plt.xticks(range(len(predictors)), predictors, rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.817059483726\n"
     ]
    }
   ],
   "source": [
    "# Pick only the four best features\n",
    "predictors = [\"Pclass\", \"Sex\", \"Fare\", \"Title\"]\n",
    "alg = RandomForestClassifier(random_state=1, n_estimators=50, min_samples_split=8, min_samples_leaf=4)\n",
    "\n",
    "# Compute the accuracy score for all the cross validation folds\n",
    "scores = cross_validation.cross_val_score(alg, titanic[predictors], titanic[\"Survived\"], cv=3)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient boosting and ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.819304152637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DaSom\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:30: FutureWarning: in the future, boolean array-likes will be handled as a boolean array index\n"
     ]
    }
   ],
   "source": [
    "# Ensemble logistic regression trained on the most linear predictors and a gradient boosted tree trained on all of the predictors\n",
    "algorithms = [\n",
    "    [GradientBoostingClassifier(random_state=1, n_estimators=25, max_depth=3), [\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\", \"FamilySize\", \"Title\", \"FamilyId\"]],\n",
    "    [LogisticRegression(random_state=1), [\"Pclass\", \"Sex\", \"Fare\", \"FamilySize\", \"Title\", \"Age\", \"Embarked\"]]\n",
    "]\n",
    "\n",
    "kf = KFold(titanic.shape[0], n_folds=3, random_state=1)\n",
    "\n",
    "predictions = []\n",
    "for train, test in kf:\n",
    "    train_target = titanic[\"Survived\"].iloc[train]\n",
    "    full_test_predictions = []\n",
    "    for alg, predictors in algorithms:\n",
    "        alg.fit(titanic[predictors].iloc[train,:], train_target)\n",
    "        # Predict the test fold\n",
    "        # Convert the dataframe to floats\n",
    "        test_predictions = alg.predict_proba(titanic[predictors].iloc[test,:].astype(float))[:,1]\n",
    "        full_test_predictions.append(test_predictions)\n",
    "    # Average the predictions to get the final classification\n",
    "    test_predictions = (full_test_predictions[0] + full_test_predictions[1]) / 2\n",
    "    # Value over 0.5 is assumed to be 1 and below 0.5 is a 0 prediction\n",
    "    test_predictions[test_predictions <= .5] = 0\n",
    "    test_predictions[test_predictions > .5] = 1\n",
    "    predictions.append(test_predictions)\n",
    "\n",
    "# Concatenate predictions\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = sum(predictions[predictions == titanic[\"Survived\"]]) / len(predictions)\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Match changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     240\n",
      "2      79\n",
      "3      72\n",
      "4      21\n",
      "7       2\n",
      "6       2\n",
      "10      1\n",
      "5       1\n",
      "Name: Title, dtype: int64\n",
      "{'Patchett0': 480, 'Turpin1': 41, 'McGowan0': 23, 'Betros0': 330, 'Smiljanic0': 148, 'Wheadon0': 33, 'Jarvis0': 488, 'Newell1': 197, 'Berglund0': 207, 'Andrew0': 135, 'Hoyt1': 206, 'Kenyon1': 392, 'Meo0': 142, 'Peters0': 557, 'Klasen2': 161, 'Denkoff0': 297, 'Carter1': 226, 'Abbott2': 252, 'Holverson1': 35, 'Turja0': 555, 'Gale1': 348, 'Maenpaa0': 221, 'Saalfeld0': 270, 'Hodges0': 586, 'Wiklund1': 325, 'Lundahl0': 522, 'Hale0': 164, 'Angle1': 439, 'Gilnagh0': 146, 'Partner0': 295, 'Cleaver0': 576, 'Sunderland0': 202, 'Tobin0': 627, \"O'Driscoll0\": 47, 'Lievens0': 622, 'Ryerson4': 280, 'Palsson4': 8, 'Burns0': 298, 'Emir0': 26, 'Olsen0': 144, 'Natsch1': 247, 'Sivola0': 159, 'Gillespie0': 585, 'Lemberopolous0': 673, 'Penasco y Castellana1': 276, 'Beckwith2': 225, 'Duane0': 253, 'Rouse0': 413, 'Meyer0': 649, 'Mockler0': 315, 'Hirvonen1': 411, 'Jalsevac0': 390, 'Jacobsohn1': 199, 'McCarthy0': 7, 'Cherry0': 234, 'Sinkkonen0': 603, 'Hocking4': 625, 'de Mulder0': 258, 'Bateman0': 140, 'McKane0': 342, 'Marechal0': 669, 'Thorne0': 233, 'Kraeff0': 42, 'Bowerman1': 312, 'de Messemaeker1': 469, 'Risien0': 453, 'Knight0': 593, 'Navratil2': 138, 'Jussila0': 483, 'Vander Cruyssen0': 689, 'Hays0': 279, 'Andrews0': 647, 'Slayter0': 290, 'Stanley0': 420, 'Nasser1': 10, 'Holm0': 657, 'Calic0': 153, 'Maisner0': 399, 'Kallio0': 374, 'Skoog5': 63, 'Vander Planke1': 19, 'Osen0': 129, 'Lahtinen2': 281, 'Moss0': 104, 'Laitinen0': 427, 'Staneff0': 74, 'Rogers0': 45, 'Widener2': 329, 'Bengtsson0': 152, 'Beane1': 456, 'Ilett0': 82, 'Slabenoff0': 499, 'Green0': 204, 'Bjornstrom-Steffansson0': 371, 'Frolicher2': 454, 'Parkes0': 251, 'Coleff0': 435, 'Gallagher0': 573, 'Shorney0': 92, 'Calderhead0': 575, 'Hood0': 70, 'Hickman2': 115, 'Thorneycroft1': 372, 'Lindahl0': 223, 'Balkic0': 688, 'Brown0': 177, 'Rommetvedt0': 545, 'Watt0': 151, 'Butler0': 544, \"O'Brien0\": 463, 'White1': 99, 'Padro y Manent0': 459, 'Johansson0': 100, 'Wright0': 466, 'Crease0': 67, 'Nakid2': 333, 'Alhomaki0': 670, 'Barton0': 109, 'Bishop1': 263, 'Laroche3': 43, 'Young0': 291, 'Rosblom2': 231, 'Davies0': 336, 'Weisz1': 125, 'Sdycoff0': 352, 'Markoff0': 676, 'Norman0': 472, 'Boulos0': 497, 'Ilmakangas1': 591, 'del Carlo1': 316, 'Van Impe2': 361, 'Barber0': 262, 'Gee0': 397, 'Elsbury0': 494, 'Novel0': 57, 'Colley0': 542, 'Goldsmith2': 154, 'Sage10': 149, 'Pasic0': 666, 'Thayer2': 461, 'Hocking3': 449, 'Brown2': 548, 'Rothschild1': 434, 'Hays2': 658, 'Turkula0': 414, 'Gronnestad0': 621, 'Torber0': 501, 'Lehmann0': 339, 'Asim0': 318, 'Daly0': 432, \"O'Dwyer0\": 28, 'Frolicher-Stehli2': 489, 'Yousseff0': 421, 'Andersson0': 137, 'Jermyn0': 322, 'Mernagh0': 179, 'Harper1': 52, 'Todoroff0': 29, 'Landergren0': 328, 'Shelley1': 693, 'Walker0': 436, 'Simonius-Blumer0': 531, 'Salonen0': 448, 'Klaber0': 578, 'Duff Gordon1': 467, 'Lefebre4': 162, 'Clifford0': 408, 'Sjoblom0': 635, 'Boulos2': 131, 'Seward0': 383, 'Vander Planke2': 38, 'Aks1': 678, 'Andreasson0': 88, 'Fischer0': 561, 'Rush0': 479, 'Sundman0': 356, 'McNamee1': 601, 'Hart0': 353, 'Dennis0': 288, 'Leyson0': 213, 'Davidson1': 549, 'Newsom2': 128, 'Meanwell0': 474, 'Garfirth0': 614, 'Foreman0': 387, 'Hamalainen2': 224, 'Barkworth0': 521, 'Svensson0': 424, 'Jonsson0': 477, 'Wiseman0': 366, 'Sandstrom2': 11, 'Niskanen0': 345, 'Harrison0': 238, 'Leonard0': 165, 'Johanson0': 184, 'Richards5': 376, 'Hansen2': 680, 'Long0': 632, 'Kantor1': 96, 'Stoytcheff0': 475, 'Sloper0': 24, 'Zimmerman0': 364, 'Hanna0': 268, 'Taussig2': 237, 'Doling1': 95, 'Burke0': 134, 'Ryan0': 438, 'Petroff0': 98, 'Compton2': 665, 'Abelson1': 277, 'Andersen-Jensen1': 176, 'Carbines0': 175, 'Vovk0': 442, 'Sutton0': 516, 'Osman0': 642, 'Stone0': 662, 'Henry0': 239, 'Asplund6': 25, 'Saundercock0': 13, 'Plotcharsky0': 335, 'Astor1': 571, 'Slocovski0': 85, 'Cumings1': 2, 'Harmer0': 634, 'Becker3': 167, 'Silverthorne0': 572, 'Blackwell0': 300, 'Karun1': 564, 'Spedden2': 287, 'Peduzzi0': 389, 'Gaskell0': 637, 'Hogeboom1': 618, 'Maioni0': 428, 'Jansson0': 341, \"O'Sullivan0\": 426, 'Meek0': 357, 'Dahl0': 299, 'Morley0': 396, 'Hewlett0': 16, 'Chip0': 668, 'Hagland1': 386, 'Hampe0': 378, 'Heininen0': 655, 'Richard0': 127, 'Douglas1': 457, 'Tomlin0': 653, 'Thomas1': 645, 'Touma2': 232, 'Coxon0': 91, 'Drazenoic0': 122, 'Toomey0': 393, 'Johnson0': 273, 'Caldwell2': 76, 'Healy0': 248, 'Hansen0': 514, 'Pain0': 343, 'McCoy2': 272, 'Vande Walle0': 183, 'Ross0': 486, 'Stranden0': 602, 'Ibrahim Shawah0': 643, 'Dodge2': 382, 'Wick2': 286, 'Kink-Heilmann2': 168, 'Milling0': 398, 'Laleff0': 691, 'Marvin1': 604, 'Duran y More1': 685, 'Dick1': 563, 'Anderson0': 395, 'Coutts2': 305, 'Jensen1': 584, 'Fox0': 303, 'Lobb1': 230, 'Ball0': 293, 'Chaffee1': 89, 'Weir0': 567, 'Phillips0': 368, 'Richards2': 350, 'Downton0': 485, 'Bailey0': 611, 'Soholt0': 580, 'Perkin0': 194, 'Nilsson0': 284, 'Corn0': 147, 'Eustis1': 422, 'Panula5': 50, 'Saad0': 566, 'Swift0': 682, 'McMahon0': 118, 'Johannesen-Bratthammer0': 381, 'Dantcheff0': 639, 'Moran1': 106, 'Bracken0': 203, 'Jussila1': 110, 'Kimball1': 513, 'Isham0': 163, 'Sirayanian0': 60, 'Jenkin0': 69, 'Abbing0': 675, 'Sjostedt0': 212, 'Nosworthy0': 51, 'Emanuel0': 628, 'Dimic0': 306, 'Hawksford0': 599, 'Bidois0': 332, 'Smart0': 402, 'Buss0': 337, 'Heikkinen0': 3, 'Lurette0': 178, 'Augustsson0': 663, 'Baumann0': 156, 'Otter0': 640, 'Cairns0': 244, 'Chronopoulos1': 71, 'Zabour1': 108, 'Moor1': 607, 'Givard0': 195, 'Cavendish1': 600, 'Guggenheim0': 636, 'Warren1': 320, 'Eklund0': 617, 'Albimona0': 189, 'Elias0': 624, 'Pernot0': 166, 'Moubarek2': 65, 'Minahan1': 354, 'Behr0': 700, 'Doharr0': 476, 'Yrois0': 182, 'Baclini3': 384, 'Banfield0': 696, 'Chambers1': 587, 'Lewy0': 267, 'Odahl0': 307, 'Cook0': 546, 'Allison3': 269, 'Adams0': 346, 'Williams1': 145, 'Hakkarainen1': 133, 'Cunningham0': 355, 'Strom1': 187, 'Larsson0': 211, 'Fynney0': 21, 'Masselmani0': 20, 'Dakic0': 560, 'Rice5': 17, 'Myhrman0': 626, 'Lemore0': 437, 'Alexander0': 650, 'Strandberg0': 407, 'Levy0': 264, 'Gill0': 683, 'Bissette0': 243, 'Windelov0': 417, 'Dowdell0': 77, 'Renouf1': 409, 'Drew2': 358, 'Kalvik0': 534, 'Nysten0': 132, 'Sobey0': 126, 'Carr0': 190, 'Carter3': 340, 'Vestrom0': 15, 'Ringhini0': 327, 'Allen0': 5, 'Baxter1': 114, 'Brocklebank0': 509, 'Fortune5': 27, 'Montvila0': 698, 'Artagaveytia0': 419, 'Quick2': 429, 'Perreault0': 441, 'Harder1': 324, 'van Billiard2': 143, 'Lindqvist1': 543, 'Ohman0': 465, 'Hedman0': 646, 'Nicola-Yarred1': 39, 'Harris0': 201, 'Aubart0': 323, 'Olsson0': 254, 'Nicholson0': 458, 'Kvillner0': 377, 'Goodwin7': 59, 'Nenkoff0': 205, 'Trout0': 344, 'Backstrom3': 83, 'Williams-Lambert0': 308, 'Kelly0': 271, 'Moran0': 6, 'Birkeland0': 351, 'Murdlin0': 491, 'Danoff0': 289, 'Charters0': 363, 'Mangan0': 620, 'Braund1': 1, 'Davis0': 525, 'Allum0': 664, 'Hosono0': 260, 'Strom2': 228, 'Caram1': 482, 'Campbell0': 401, 'Widegren0': 349, 'Cann0': 37, 'Najib0': 690, 'de Pelsmaeker0': 255, 'Jensen0': 527, 'Rothes0': 613, 'Persson1': 241, 'Celotti0': 86, 'Molson0': 418, 'Carlsson0': 610, 'Meyer1': 34, 'Nankoff0': 598, 'Mellors0': 208, 'Moraweck0': 285, 'Harknett0': 214, 'Garside0': 481, 'Canavan0': 425, 'Jacobsohn3': 498, 'Lesurer0': 596, 'Greenfield1': 94, 'Stephenson1': 493, 'Robins1': 124, 'Cor0': 530, 'Herman3': 510, 'Mallet2': 656, \"O'Brien1\": 170, 'Berriman0': 594, 'Moore0': 116, 'Peuchen0': 385, 'Bystrom0': 684, 'Devaney0': 44, 'Sawyer0': 554, 'McGovern0': 314, 'Sedgwick0': 302, 'Cardeza1': 556, 'Pettersson0': 648, 'Sirota0': 667, 'Collyer2': 216, 'Bourke2': 172, 'Connolly0': 261, 'Murphy1': 219, 'Romaine0': 171, 'Nysveen0': 292, 'Chapman1': 495, 'Mudd0': 671, \"O'Leary0\": 535, 'Dahlberg0': 695, 'Crosby2': 455, 'Elias2': 309, 'Bonnell0': 12, 'Faunthorpe1': 53, 'Davison1': 304, 'Ayoub0': 631, 'Leeni0': 464, 'Haas0': 265, 'Beavan0': 326, 'Rintamaki0': 492, 'Peter2': 120, 'Chapman0': 568, 'Futrelle1': 4, 'Youseff0': 185, 'Pickard0': 370, 'Honkanen0': 198, 'Morrow0': 470, 'Butt0': 451, 'West3': 58, 'Carrau0': 81, 'Mitkoff0': 533, 'Leinonen0': 526, 'Stead0': 229, 'McEvoy0': 583, 'Flynn0': 369, 'Pavlovic0': 440, 'Hassan0': 592, 'Sadlier0': 338, 'Cameron0': 193, 'Mullens0': 569, 'Johnston3': 633, 'Jonkoff0': 609, 'Andrews1': 249, 'Shutes0': 506, 'Kiernan1': 196, 'Ridsdale0': 446, 'Shellard0': 423, 'Pengelly0': 217, 'Parr0': 524, 'Mineff0': 266, 'Wilhelms0': 551, 'Farthing0': 447, 'Webber0': 117, 'Taylor1': 547, 'Frauenthal1': 296, 'Pears1': 141, 'Gustafsson0': 331, 'Connaghton0': 605, 'Lindblom0': 250, 'Badt0': 541, 'Daniel0': 505, 'Arnold-Franchi1': 49, 'Giles1': 681, 'Moussa0': 321, 'Mayne0': 577, 'Funk0': 313, 'Leader0': 641, 'Kilgannon0': 629, 'Reeves0': 240, 'Slemen0': 652, 'Francatelli0': 278, 'van Melkebeke0': 687, 'Brewe0': 619, 'Karlsson0': 410, 'Mack0': 623, 'Bazzani0': 200, 'Appleton2': 478, 'Lester0': 651, 'Rekic0': 105, 'Johnson2': 9, 'Keane0': 274, 'Oreskovic0': 347, 'Scanlan0': 403, 'Horgan0': 508, 'Van der hoef0': 158, 'Uruchurtu0': 30, 'Tornquist0': 245, 'Coelho0': 123, 'Danbom2': 365, 'Jardin0': 507, 'Theobald0': 612, 'Graham0': 699, 'Christmann0': 87, 'Razi0': 679, 'Gilinski0': 490, 'Madigan0': 181, 'Andersson6': 14, 'Ponesell0': 644, 'Somerton0': 416, 'Connors0': 113, 'Backstrom1': 188, 'Wells2': 606, 'Kassem0': 444, 'Woolner0': 55, 'Naidenoff0': 259, 'Toufik0': 450, 'Mellinger1': 246, 'Jerwan0': 406, 'Attalah0': 111, 'Spencer1': 31, 'Goldschmidt0': 93, 'Parrish1': 236, 'Eitemiller0': 538, 'Potter1': 692, 'Lennon1': 46, 'Pekoniemi0': 112, 'Rugg0': 56, 'Watson0': 552, 'Turcin0': 173, 'Hegarty0': 536, 'Simmons0': 473, 'Hart2': 283, 'Moutal0': 75, 'Hold1': 215, 'Mionoff0': 102, 'Gheorgheff0': 362, 'Giglio0': 130, \"O'Connor0\": 394, 'Fleming0': 275, 'Goncalves0': 400, 'Pinsky0': 174, 'Stahelin-Maeglin0': 523, 'Ostby1': 54, 'Troupiansky0': 595, 'Byles0': 139, 'Mannion0': 589, 'Bing0': 72, 'Reed0': 227, 'Robert1': 630, 'Madsen0': 119, 'Paulner0': 487, 'Cribb1': 150, 'Graham1': 242, 'Sutehall0': 697, 'Sagesser0': 528, 'Cacic0': 405, 'Collander0': 301, 'Lines1': 677, 'Humblen0': 570, 'Olsen1': 180, 'Bradley0': 430, 'Christy2': 484, 'Barah0': 616, 'Frauenthal2': 540, 'Matthews0': 360, 'Lindell1': 503, 'Petranec0': 97, 'Hansen1': 574, 'Markun0': 694, 'Bostandyeff0': 519, 'Icard0': 61, 'Fahlstrom0': 210, 'Culumovic0': 674, 'Sheerlinck0': 79, 'Yousif0': 310, 'Gustafsson2': 101, 'Leitch0': 496, 'Hoyt0': 638, 'Lulic0': 659, 'Minahan2': 222, 'Hassab0': 558, 'Silvey1': 375, 'Smith0': 160, 'Yasbeck1': 512, 'Coleridge0': 220, 'Stankovic0': 257, 'McGough0': 433, 'Robbins0': 468, 'McDermott0': 80, 'Porter0': 107, 'Barbara1': 317, 'Dean3': 90, 'Ivanoff0': 597, 'Moen0': 73, 'Homer0': 502, 'Beesley0': 22, 'Dooley0': 701, 'Frost0': 412, 'Bryhl1': 590, 'Sharp0': 462, 'Blank0': 191, 'Sivic0': 471, 'Rood0': 169, 'Hendekovic0': 282, 'Roebling0': 686, 'Lahoud0': 443, 'Samaan2': 48, 'Radeff0': 537, 'Louch1': 373, 'Madill1': 562, 'McCormack0': 661, 'Endres0': 581, 'Kirkland0': 517, 'Hunt0': 218, 'Kent0': 415, 'Gavey0': 511, 'Serepeca0': 672, 'Millet0': 391, 'Cohen0': 186, 'Lam0': 565, 'Ling0': 157, 'Renouf3': 588, 'Vande Velde0': 608, 'Tikkanen0': 334, \"O'Connell0\": 520, 'Salkjelsvik0': 103, 'Goldenberg1': 388, 'Farrell0': 445, 'Dorking0': 256, 'Nye0': 66, 'Chibnall1': 155, 'Davies2': 460, 'Lang0': 431, 'Ward0': 235, 'Petterson1': 379, 'Karaic0': 504, 'Reuchlin0': 660, 'Kink2': 68, 'Foo0': 529, 'Glynn0': 32, 'Harris1': 62, 'Olsvigen0': 559, 'Hippach1': 294, 'Nicholls2': 136, 'Ekstrom0': 121, 'Reynaldo0': 380, 'Waelens0': 78, 'Fry0': 654, 'Lovell0': 209, 'Adahl0': 319, 'Nirva0': 615, 'Bowen0': 515, 'Ford4': 84, 'Troutt0': 582, 'Newell2': 539, 'Ali0': 192, 'Edvardsson0': 553, 'Silven2': 359, 'Longley0': 518, 'Stewart0': 64, 'LeRoy0': 452, 'Keefe0': 404, 'Mamee0': 36, 'Ahlin1': 40, 'Harrington0': 500, 'Willey0': 532, 'Vanden Steen0': 311, 'Clarke1': 367, 'Williams0': 18, 'Mitchell0': 550, 'Greenberg0': 579}\n"
     ]
    }
   ],
   "source": [
    "# Add titles to the test set\n",
    "titles = titanic_test[\"Name\"].apply(get_title)\n",
    "# Add Dona title to the training set\n",
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Dr\": 5, \"Rev\": 6, \"Major\": 7, \"Col\": 7, \"Mlle\": 8, \"Mme\": 8, \"Don\": 9, \"Lady\": 10, \"Countess\": 10, \"Jonkheer\": 10, \"Sir\": 9, \"Capt\": 7, \"Ms\": 2, \"Dona\": 10}\n",
    "for k,v in title_mapping.items():\n",
    "    titles[titles == k] = v\n",
    "titanic_test[\"Title\"] = titles\n",
    "print(pandas.value_counts(titanic_test[\"Title\"]))\n",
    "\n",
    "# Add \"FamilySize\"\n",
    "titanic_test[\"FamilySize\"] = titanic_test[\"SibSp\"] + titanic_test[\"Parch\"]\n",
    "\n",
    "# Add \"FamilyId\"\n",
    "print(family_id_mapping)\n",
    "family_ids = titanic_test.apply(get_family_id, axis=1)\n",
    "family_ids[titanic_test[\"FamilySize\"] < 3] = -1\n",
    "titanic_test[\"FamilyId\"] = family_ids\n",
    "titanic_test[\"NameLength\"] = titanic_test[\"Name\"].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Predict the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\", \"FamilySize\", \"Title\", \"FamilyId\"]\n",
    "\n",
    "algorithms = [\n",
    "    [GradientBoostingClassifier(random_state=1, n_estimators=25, max_depth=3), predictors],\n",
    "    [LogisticRegression(random_state=1), [\"Pclass\", \"Sex\", \"Fare\", \"FamilySize\", \"Title\", \"Age\", \"Embarked\"]]\n",
    "]\n",
    "\n",
    "full_predictions = []\n",
    "for alg, predictors in algorithms:\n",
    "    alg.fit(titanic[predictors], titanic[\"Survived\"])\n",
    "    # Convert all the columns to floats for prediction\n",
    "    predictions = alg.predict_proba(titanic_test[predictors].astype(float))[:,1]\n",
    "    full_predictions.append(predictions)\n",
    "\n",
    "# Weight higher in the gradient boosting\n",
    "predictions = (full_predictions[0] * 3 + full_predictions[1]) / 4\n",
    "predictions[predictions <= .5] = 0\n",
    "predictions[predictions > .5] = 1\n",
    "predictions = predictions.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pandas.DataFrame({\n",
    "        \"PassengerId\": titanic_test[\"PassengerId\"],\n",
    "        \"Survived\": predictions\n",
    "    })\n",
    "submission.to_csv(\"kaggle_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Result: Approx. 80% of accuracy achieved"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
